/*
 * Fermat
 *
 * Copyright (c) 2016-2019, NVIDIA CORPORATION. All rights reserved.
 * 
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *    * Redistributions of source code must retain the above copyright
 *      notice, this list of conditions and the following disclaimer.
 *    * Redistributions in binary form must reproduce the above copyright
 *      notice, this list of conditions and the following disclaimer in the
 *      documentation and/or other materials provided with the distribution.
 *    * Neither the name of the NVIDIA CORPORATION nor the
 *      names of its contributors may be used to endorse or promote products
 *      derived from this software without specific prior written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE FOR ANY
 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#pragma once

#include <types.h>
#include <buffers.h>
#include <ray.h>
#include <tiled_sequence.h>
#include <cugar/sampling/lfsr.h>
#include <cugar/sampling/variance.h>
#include <cugar/linalg/bbox.h>
#include <renderer_interface.h>

struct RenderingContext;
struct MeshVTLStorage;
struct ClusteredRLStorage;
struct AdaptiveClusteredRLStorage;

/// \page PTPageCode pathtracer_impl.h
///
/// \include pathtracer_impl.h

/// \page PTPage The Path Tracer (Revisited)
/// Top: \ref OvertureContentsPage
///
/// <img src="morning-bath-rec.jpg" style="position:relative; bottom:-10px; border:0px; width:740px;"/>
///\n
///\par
/// This chapter aims to show how to use \ref PTLib library to build a much more streamlined, yet even more powerful path tracer.
///\par
/// If you take look at the full implementation in \ref PTPageCode, you should notice that the overall structure is pretty similar to that of our \ref HelloRendererPage
/// "Hello World" prototype path-tracer, yet even more compact.
/// We will skip some details and go directly to the important bits.
/// Remember that the central feature of \ref PTLib is the \ref path_trace_loop_anchor "path_trace_loop()" function, and that this is configured by a few template classes
/// that need to be provided by the user.
/// The first here is the implementation of the \ref TPTContext class:
///\n
///\snippet pathtracer_impl.h	PT::PathTracingContext
///
///\par
/// The main news here is the fact we inherited it from \ref PTContextBase and \ref PTContextQueues, and added a single member,
/// the templated \ref TPTDirectLightingSampler, \ref PathTracingContext::dl.
///
///\par
/// The \ref PathTracer::render_impl "render" method itself starts almost identically to the one we already saw:
///
///\snippet pathtracer_impl.h	PT::render-1
///
///\par
/// The main news should be the last two lines:
///
///\snippet pathtracer_impl.h	PT::instantiate_vertex_processor
///
///\par
/// i.e. the instantiation of a custom \ref TPTVertexProcessor - the second template interface that must be implemented in order to configure \ref PTLib.
/// After that, the body of the render method is almost trivial:
///
///\snippet pathtracer_impl.h	PT::render-2
///
///\par
/// You'll notice that there are two parts to it, with two different instantiations of the \ref path_trace_loop_anchor "path_trace_loop()" call:
/// they correspond to using two different direct-lighting samplers provided by Fermat, the default mesh-based sampler (\ref DirectLightingMesh, second branch),
/// which can be configured to either generate samples on the mesh triangles on the fly, or use a set of pre-sampled VPLs, and a more advanced 
/// <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement Learning</a> based sampler (\ref DirectLightingRL, first branch).
/// Other than that, the two branches are almost identical: they initialize the context with all its members, and call into \ref path_trace_loop_anchor "path_trace_loop()".
///
///\par
/// So what does our vertex processor do, exactly?
/// It implements a few methods specifying how to weight and accumulate the path samples generated by \ref path_trace_loop_anchor "path_trace_loop()".
/// The first such method handles the calculation of Next-Event Estimation (NEE) weights:
///
///\snippet pathtracer_vertex_processor.h	PTVertexProcessor::compute_nee_weights
///
///\par
/// The relevant lines are just these:
///
///\snippet pathtracer_vertex_processor.h	PTVertexProcessor::compute_nee_weights_body
///
///\par
/// For now we'll focus on the first two, and ignore the third and last line; we'll come back to that later.
/// The first says that output diffuse weight, <i>out_w_d</i> should be equal to the local diffuse BSDF component <i>f_d</i>, times the light's EDF <i>f_L</i>, times the path weight <i>w</i>
/// if this is the very first vertex along a path (i.e. the one directly visible from the camera), and otherwise it should be the sum of both the diffuse and glossy
/// components <i>(f_d + f_g)</i>, times the EDF and the path weight.
/// The rationale for this distinction is that this path tracer supports splitting the output to distinct framebuffer channels for diffuse and specular components, and this output diffuse
/// weight is what will be eventually accumulated into the <i>diffuse</i> channel, and we want it to
/// contain the diffuse direct lighting at the first bounce, plus <i>all</i> the indirect lighting (whether glossy or diffuse) seen through any <i>previous diffuse scattering event</i>.
/// The output glossy weight <i>out_w_g</i> is computed with similar logic.
///
///\par
/// At this point you might wonder how we're going to find out whether this sample did go through some previous scattering event, and we will find the answer examining the next method,
/// specifying the recipe for the actual sample accumulation:
///
///\snippet pathtracer_vertex_processor.h PTVertexProcessor::accumulate_nee
///
///\par
/// Here you can notice that, again, we have some special casing for the first bounce - which adds both the diffuse and the glossy sample values to their respective channels -
/// and another case for all other bounces - which selectively write to <i>either</i> the diffuse <i>or</i> the glossy channel based on the <i>pixel_info.comp</i> field, which is
/// exactly what \ref PTLib uses to mark whether a path is diffuse or glossy (or in other words, whether the first scattering event as seen from the camera was diffuse or glossy).
///
///\par
/// The next method we should look at is the one specifying the assignment of the new path weight after a scattering event:
///
///\snippet pathtracer_vertex_processor.h	PTVertexProcessor::compute_scattering_weights
///
///\par
/// and again, besides the function signature boilerplate, this method is very simple: it says that the output path weight <i>out_w</i> should be the product of the local BSDF scattering
/// weight <i>g</i> (which is calculated as the BSDF value divided by the sampling pdf, i.e. <i>g = f/p</i>), times the current path weight <i>w</i>.
///
///\par
/// Finally, we'll look at the recipe for accumulating emissive vertices found along a path:
///
///\snippet pathtracer_vertex_processor.h	PTVertexProcessor::accumulate_emissive
///
///\par
/// and hopefully at this point you sort of understand what's going on: the emissive sample <i>w</i> is simply accumulated to the various framebuffer channels it contributes to,
/// again depending on whether this is the first bounce (in which case the sample represents direct lighting), or a secondary one.
///
///\par
/// This should more or less clarify how to use \ref PTLib. More importantly, it should clarify what it is designed for: implementing massively parallel, <i>customizable</i> path tracers, without
/// actually writing any of the relatively complex kernel and queueing logic necessary to implement them.
/// In the next chapter, we'll see a more advanced use case, where the same exact library is customized to perform path space filtering.
/// Incidentally, so far we didn't quite explain what were all those <i>packed vertex_info</i>'s that we blatantly initialized to 0xFFFFFFFF (essentially marking them <i>unused</i>):
/// the next section will show what they can be used for.
///
/// 
/// Next: \ref PSFPTPage

///@addtogroup Fermat
///@{

///@defgroup PTModule
/// This module defines a path tracing renderer implemented on top of the \ref PTLib library.
///@{

enum NEEAlgorithm {
	NEE_ALGORITHM_MESH	= 0,
	NEE_ALGORITHM_VPL	= 1,
	NEE_ALGORITHM_RL	= 2
};

/// Path tracer renderer options
///
struct PTOptions
{
	uint32	max_path_length;
	uint32	direct_lighting			: 1;
	uint32	direct_lighting_nee		: 1;
	uint32	direct_lighting_bsdf	: 1;
	uint32	indirect_lighting_nee	: 1;
	uint32	indirect_lighting_bsdf	: 1;
	uint32	visible_lights			: 1;
	uint32	diffuse_scattering		: 1;
	uint32	glossy_scattering		: 1;
	uint32	indirect_glossy			: 1;
	uint32	rr						: 1;
	uint32	nee_type				: 2;
	uint32	backend;

	#if !defined(OPTIX_COMPILATION)
	PTOptions() :
		max_path_length(6),
		direct_lighting_nee(true),
		direct_lighting_bsdf(true),
		indirect_lighting_nee(true),
		indirect_lighting_bsdf(true),
		visible_lights(true),
		direct_lighting(true),
		diffuse_scattering(true),
		glossy_scattering(true),
		indirect_glossy(false),
		rr(true),
		nee_type(NEE_ALGORITHM_VPL),
		backend(0) {}
	#endif

	void parse(const int argc, char** argv)
	{
		for (int i = 0; i < argc; ++i)
		{
			if (strcmp(argv[i], "-pl") == 0 ||
				strcmp(argv[i], "-path-length") == 0 ||
				strcmp(argv[i], "-max-path-length") == 0)
				max_path_length = atoi(argv[++i]);
			else if (strcmp(argv[i], "-bounces") == 0)
				max_path_length = atoi(argv[++i]) + 1;
			else if (strcmp(argv[i], "-nee") == 0)
				direct_lighting_nee = indirect_lighting_nee = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-bsdf") == 0)
				direct_lighting_bsdf = indirect_lighting_bsdf = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-direct-nee") == 0)
				direct_lighting_nee = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-direct-bsdf") == 0)
				direct_lighting_bsdf = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-indirect-nee") == 0)
				indirect_lighting_nee = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-indirect-bsdf") == 0)
				indirect_lighting_bsdf = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-visible-lights") == 0)
				visible_lights = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-direct-lighting") == 0)
				direct_lighting = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-indirect-glossy") == 0)
				indirect_glossy = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-diffuse") == 0)
				diffuse_scattering = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-glossy") == 0)
				glossy_scattering = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-rr") == 0)
				rr = atoi(argv[++i]) > 0;
			else if (strcmp(argv[i], "-nee-algorithm") == 0 ||
					 strcmp(argv[i], "-nee-alg") == 0)
			{
				if (strcmp(argv[i+1], "mesh") == 0)
					nee_type = NEE_ALGORITHM_MESH;
				else if (strcmp(argv[i+1], "vpl") == 0)
					nee_type = NEE_ALGORITHM_VPL;
				else if (strcmp(argv[i+1], "rl") == 0)
					nee_type = NEE_ALGORITHM_RL;

				++i;
			}
		}
	}
};

/// Path tracer stats
///
struct PTStats
{
	cugar::Variance_estimator<float> primary_rt_time;
	cugar::Variance_estimator<float> path_rt_time;
	cugar::Variance_estimator<float> shadow_rt_time;
	cugar::Variance_estimator<float> path_shade_time;
	cugar::Variance_estimator<float> shadow_shade_time;
};

/// Path tracer
///
struct PathTracer : RendererInterface
{
	//typedef ClusteredRLStorage	VTLRLStorage;
	typedef AdaptiveClusteredRLStorage	VTLRLStorage;

	PathTracer();

	void init(int argc, char** argv, RenderingContext& renderer);

	void render(const uint32 instance, RenderingContext& renderer);

	void setup_samples(const uint32 instance);

	void keyboard(unsigned char character, int x, int y, bool& invalidate);

	void destroy() { delete this; }

	void dump_speed_stats(FILE* stats);

	void update_vtls_rl(const uint32 instance);

	static RendererInterface* factory() { return new PathTracer(); }

	DomainBuffer<CUDA_BUFFER, uint8>	m_memory_pool;

	PTOptions					m_options;
	TiledSequence				m_sequence;

	cugar::LFSRGeneratorMatrix  m_generator;
	cugar::LFSRRandomStream		m_random;

	MeshVTLStorage*				m_mesh_vtls;
	VTLRLStorage*				m_vtls_rl;
	cugar::Bbox3f				m_bbox;

	float						m_time;

	uint32						m_pathtracer_raygen;

	PTStats						m_stats;
};

///@} PTModule
///@} Fermat
