/*
 * cugar
 * Copyright (c) 2011-2014, NVIDIA CORPORATION. All rights reserved.
 * 
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *    * Redistributions of source code must retain the above copyright
 *      notice, this list of conditions and the following disclaimer.
 *    * Redistributions in binary form must reproduce the above copyright
 *      notice, this list of conditions and the following disclaimer in the
 *      documentation and/or other materials provided with the distribution.
 *    * Neither the name of the NVIDIA CORPORATION nor the
 *      names of its contributors may be used to endorse or promote products
 *      derived from this software without specific prior written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE FOR ANY
 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

// \mainpage CUGAR

///\page cugar_page CUGAR
///
///\htmlonly
/// <img src="nvidia_cubes.png" style="position:relative; bottom:-10px; border:0px;"/>
///\endhtmlonly
///
///\par
///\n
/// <b>CUGAR</b>, the CUDA Graphics AcceleratoR, is a library of reusable components designed to accelerate
/// CUDA based graphics applications.
/// Though it is specifically designed to unleash the power of <i>NVIDIA</i> <b>GPU</b>s, most of its components
/// are completely cross-platform and can be used both from host C++ and device
/// CUDA code.
///
/// \section IntroductionSection Introduction
///
/// - \subpage generic_programming_page
/// - \subpage host_device_page
///
/// \section ModulesSection Modules
///\par
/// CUGAR includes the following modules:
///
/// - \subpage basic_page
/// - \subpage bits_page
/// - \subpage linalg_page
/// - \subpage bintree_page
/// - \subpage radixtree_page
/// - \subpage bvh_page
/// - \subpage kd_page
/// - \subpage bsdf_page
/// - \subpage sampling_page
/// - \subpage spherical_page
/// - \subpage tree_page
///
///
/// \section DependenciesSection Dependencies
///\par
/// CUGAR depends on the following external libraries:
///
/// - <a href="http://nvlabs.github.io/cub/">CUB</a>
/// - a modification of Nathaniel McClatchey's <a href="https://github.com/nmcclatchey/Priority-Deque/">priority_deque</a>
///
/// \section Licensing
///\par
/// CUGAR has been developed by <a href="www.nvidia.com">NVIDIA Corporation</a> and is licensed under BSD.
///
/// \section Contributors
///\par
/// CUGAR is made and mantained by <a href="jpantaleoni@nvidia.com">Jacopo Pantaleoni</a>.
///
///\htmlonly
/// <a href="http://research.nvidia.com"><img src="cuda_small.png" style="position:relative; bottom:-10px; border:0px;"/></a>
/// &nbsp;&nbsp;
///\endhtmlonly

/// \page host_device_page Host & Device
///\par
/// The user of CUGAR needs to familiarize with the fact that on a GPU equipped system
/// there is both a <i>host</i>, controlled by a <i>CPU</i>, and one or multiple <i>GPU</i> <i>devices</i>,
/// with distinct memory spaces.
/// Hence, there can be several types of functions and data-structures:
///\par
/// - single-threaded functions that can be called by a host thread
/// - single-threaded functions that can be called by a device thread
/// - single-threaded functions that can be called both on the host and the device
/// - parallel functions that can be called by a host thread, and spawn one or more sets of host threads
/// - parallel functions that can be called by a host thread, but spawn one or more sets of device threads
///\par
/// - data-structures that encapsulate host data and are meant to be used on the host
///   (e.g. a resizable host vector, cugar::vector<host_tag,T>)
/// - data-structures that encapsulate device data but are meant to be used on the host
///   (e.g. a resizable device vector, cugar::vector<device_tag,T>)
/// - data-structures that encapsulate device data and are meant to be used on the device
///\par
/// Unified Virtual Memory allows to use any data-structure anywhere, but for performance-oriented applications
/// it can be beneficial to have explicit control of placement in the memory hierarchy.
///
/// \section PlainViewsSection Plain Views
///\par
/// The fact that some data structures contain device data but can only be used from the host,
/// coupled with the fact that at the moment CUDA does not allow to pass references
/// as device kernel arguments and requires to pass PODs in, lends naturally to the definition of
/// <i>plain views</i>: in CUGAR's speech, a plain view of an object is essentially a <i>shallow reference</i>
/// to an object's data encapsulated in a POD data structure that can be passed as kernel parameters.
///\par
/// CUGAR defines the generic function plain_view() to obtain the plain view of a given object.
/// Analogously it defines the meta function plain_view_subtype<T>::type to get the type of the
/// plain view of any given type T (where defined).
/// Moreover, as a convention CUGAR's data structures T define the subtype T::plain_view_type and
/// T::const_plain_view_type to identify their plain view types.
///\par
/// As an example consider the following situation, where on the host you have created a large device vector
/// you want to be filled by a device kernel.
/// Ideally, you'd want to simply pass a reference to the vector to your kernel, as in:
///\code
/// __global__ void my_kernel(                   // the CUDA kernel
///     cugar::vector<device_tag,uint32>& vec)   // ideally, receive a reference: doesn't work without UVM!
/// {
///     const uint32 tid = threadIdx.x + blockIdx.x * blockDim.x; // compute a linear thread id
///     if (tid < vec.size())
///         vec[tid] = tid * 10;
/// }
///
/// int main()
/// {
///     cugar::vector<device_tag,uint32> vec( 1000000 );
///
///     const uint32 blockdim = 128;
///     const uint32 n_blocks = util::divide_ri( vec.size(), blockdim ); 
///     my_kernel<<<n_blocks,blockdim>>>( vec );
/// }
///\endcode
///\par
/// With UVM-capable GPUs this is technically possible, though it requires page migration. With CUGAR, you can do this instead:
///\code
/// __global__ void my_kernel(                   // the CUDA kernel
///     cugar::vector_view<uint32> vec)          // CUGAR's surrogate of a reference
/// {
///     const uint32 tid = threadIdx.x + blockIdx.x * blockDim.x; // compute a linear thread id
///     if (tid < vec.size())
///         vec[tid] = tid * 10;
/// }
///
/// int main()
/// {
///     cugar::vector<device_tag,uint32> vec( 1000000 );
///
///     const uint32 blockdim = 128;
///     const uint32 n_blocks = util::divide_ri( vec.size(), blockdim );
///     my_kernel<<<n_blocks,blockdim>>>( cugar::plain_view( vec ) );
/// }
///\endcode
///\par
/// This basic pattern can be applied to all of CUGAR's data structures that are meant to be setup from the
/// host and accessed from the device.
///
/// Next: \ref hello_cugar_page

/// \page generic_programming_page Generic Programming
///\par
/// Most of CUGAR's functions and data structures are <em>C++ templates</em>
/// providing the flexibility and compile-time code generation needed
/// to accomodate the exponential amount of type combinations possible in typical
/// applications.
///\par
/// Just as an example, consider the following code, building a K-d tree over a set of points:
///\par
/// The following code snippet shows how to use this builder:
/// \code
///
/// #include <cugar/kd/cuda/kd_builder.h>
/// #include <cugar/kd/cuda/kd_context.h>
///
/// thrust::device_vector<Vector3f> points;
/// ... // code to fill the input vector of points
///
/// thrust::device_vector<Kd_node>  kd_nodes;
/// thrust::device_vector<uint2>    kd_leaves;
/// thrust::device_vector<uint32>   kd_index;
///
/// cugar::cuda::Kd_builder<uint64> builder( kd_index );
/// cugar::cuda::Kd_context kd_tree( &kd_nodes, &kd_leaves, NULL );
/// builder.build(
///     kd_tree,                                    // output tree
///     kd_index,                                   // output index
///     Bbox3f( Vector3f(0.0f), Vector3f(1.0f) ),   // suppose all bboxes are in [0,1]^3
///     points.begin(),                             // begin iterator
///     points.end(),                               // end iterator
///     4 );                                        // target 4 objects per leaf
/// 
///  \endcode
///
///\par
/// In the above code, the builder stores the nodes of the resulting K-d tree into a flat
/// array of Kd_node's. But what if we wanted to store them using a different layout?
/// It turns out the builder itself doesn't know anything about the actual output it produces,
/// but rather, it delegates everything to an \ref KdOutputTreeAnchor "OutputTree" template class
/// which must possess the following interface:
/// \code
/// struct OutputTree
/// {
///    void reserve_nodes(const uint32 n);  // reserve space for n nodes
///    void reserve_leaves(const uint32 n); // reserve space for n leaves
///
///    Context get_context();             // get a context to write nodes/leaves
///
///    struct Context
///    {
///        void write_node(
///           const uint32 node,          // node to write
///           const uint32 offset,        // child offset
///           const uint32 skip_node,     // skip node
///           const uint32 begin,         // node range begin
///           const uint32 end,           // node range end
///           const uint32 split_index,   // split index
///           const uint32 split_dim,     // splitting dimension
///           const uint32 split_plane);  // splitting plane
///
///        void write_node(
///           const uint32 node,          // node to write
///           const uint32 offset,        // child offset
///           const uint32 skip_node,     // skip node
///           const uint32 begin,         // node range begin
///           const uint32 end);          // node range end
///
///        void write_leaf(
///           const uint32 index,         // leaf to write
///           const uint32 begin,         // leaf range begin
///           const uint32 end);          // leaf range end
///    };
/// };
/// \endcode
///
///\par
/// allowing its behaviour to be completely customized.
/// In this case, we just relied on the default implementation provided by cugar::cuda::Kd_context.
///
/// Next: \ref host_device_page
/// Top: \ref mainpage
